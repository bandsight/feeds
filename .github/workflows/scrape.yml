name: Scrape council jobs

on:
  workflow_dispatch: {}
  schedule:
    # Every 6 hours. CRON uses UTC (AUS/Melbourne is UTC+11 on Oct 31, 2025).
    - cron: "0 */6 * * *"

permissions:
  contents: write
  actions: read

concurrency:
  group: scraper
  cancel-in-progress: false

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Ensure data/ dirs exist
        run: |
          mkdir -p data feeds

      - name: Run scraper
        run: |
          python src/scraper.py \
            --councils data/councils.yaml \
            --out data/jobs_history.jsonl \
            --append \
            --delay 0.3 \
            --log INFO

      - name: Build feeds
        run: |
          python src/feeds_site_builder.py \
            --in data/jobs_history.jsonl \
            --out feeds/feed.xml \
            --days 45

      - name: Commit & push if changed
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A
          if ! git diff --cached --quiet; then
            git commit -m "chore(scraper): update jobs_history and feed [skip ci]"
            git push
          else
            echo "No changes to commit."
          fi
